{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-large\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774030080"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация с дефолтными параметрами\n",
    "Официальный скрипт (или набор параметров) для декодирования отсутствует по [следующей причине](https://github.com/microsoft/DialoGPT#model-decoding):  \n",
    ">We note that even with properly filtered Reddit dataset, sometimes our model can still generate moderately toxic/inappropriate responses. Due to this reason, we are unable to provide the decoding script at this time (The live demo and decoding script access is upon invitation only now ). We are currently still working on a controlled decoding method to prevent this system from toxic generation. Please stay tuned.  \n",
    "\n",
    "Я взял параметры из [демки](https://huggingface.co/microsoft/DialoGPT-large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_answer(model_output, input_text_len):\n",
    "    answer = tokenizer.decode(model_output[input_text_len:], skip_special_tokens=True)\n",
    "    return answer\n",
    "\n",
    "\n",
    "def print_samples(question, top_p=None, top_k=None, temperature=None, num_beams=1,\n",
    "            repetition_penalty=None, length_penalty=None, no_repeat_ngram_size=None, num_return_sequences=1, repeat=1):\n",
    "    input_text = question\n",
    "    input_ids = tokenizer.encode(input_text + tokenizer.eos_token, return_tensors='pt').to(device)\n",
    "    for _ in range(repeat):\n",
    "        sample_outputs = model.generate(\n",
    "            input_ids,\n",
    "            do_sample=False, \n",
    "            early_stopping=False,\n",
    "            max_length=1000,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k, \n",
    "            top_p=top_p,\n",
    "            num_beams=num_beams,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            length_penalty=length_penalty,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        answers = sorted(map(lambda text: decode_answer(text, input_ids.shape[-1]-1), sample_outputs),\n",
    "                         key=len, reverse=True)\n",
    "        for answer in answers:\n",
    "            print(answer)\n",
    "            print('**********\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры из репозитория\n",
    "https://github.com/microsoft/DialoGPT  \n",
    "С дефолтными параметрами почему-то генерируются другие ответы. Больше всего похоже, что модель с того времени дообучили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It does if you're a billionaire.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples('Does money buy happiness?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think it's a reference to the movie The Office.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Отсутствие вопросительного знака творит какую-то дичь\n",
    "print_samples('who is the first president of the United States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples('who is the first president of the United States?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a unit of measurement.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples('what is the boiling point of water?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun, but it's not even close.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples('which one is bigger, sun or moon?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one with the black and white stripes.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples('which animal has black and white stripes?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be a good boy.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples('what is the meaning of life ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "England, but they were the only team to win it in the last 20 years.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples('who won the world cup in 2018 ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not a fan of the way the game looks, but the gameplay is great.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"Nvidia's Titan RTX is really good .\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure if I should be excited or scared.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"Nvidia's Titan RTX is really good.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think it's possible, but I don't think it's likely.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"Can Porsche beat Tesla with its new Taycan EV ?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think it's a pretty good car.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"Can Porsche beat Tesla with its new Taycan EV?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like it. It's a good one.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"What do you think of the DialoGPT repo ?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like it. It's a good one.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"What do you think of the DialoGPT repo?\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры из AskReddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know, but I know I've had it.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"What's the grossest thing you've ever tasted?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would have to say I would be a ninja. I would be a ninja.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"If you could have 1 superpower what would it be and why?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not wasting my time on this sub. I'm just bored.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"Is there anything you should be doing right now, but you're wasting your time on reddit instead? If so, what is it?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know, but I know it's a theory.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"What is the scariest/creepiest theory you know about?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think the point is that the assassins are not the only ones who are trained to murder.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"In the John Wick universe, assassins are shown to be everyone and everywhere, thus indicating a buyer's market. What limited time deals and offers do assassins provide to out price the competition? How does the economics of the world operate with so many trained killers?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know, but I know it's the one where Jesus is crucified.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"What is you favorite sex scene in the Bible?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I use them for the same thing as above.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"What are underrated websites and what do you use them for?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Because they're not the same people.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"Why do you hate the people that you hate?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I used to work in a photo lab. I used to work in a photo lab.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"People who used to work in photo labs before digital cameras, what weird stuff did you develop?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know what you mean by that.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"To the people who check behind the shower curtain before using the washroom; what’s the next plan if you see someone?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think it would be a warning label that said, I'm not a robot.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"If you came with a warning label, what would it be?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know, but I'm sure it's not the best decision I've made while sober.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"What is the best decision you've made while drunk?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know. I don't know. I don't know. I don't know.\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_samples(\"\"\"What’s one rule you live by?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
